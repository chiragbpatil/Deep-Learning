{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TwitterSentimentAnalysisUsingCNN.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "08869ppixH_S"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQsTFNGFhKvT"
      },
      "source": [
        "## **Here I will use CNN for text classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckg5qldthUNw"
      },
      "source": [
        "## Download Data set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqdQdYRLhpDl"
      },
      "source": [
        "**Here I will use Sentiment140 dataset**<br>\n",
        "**Source : [link text](https://www.kaggle.com/kazanova/sentiment140)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxcoiEHpgc31"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_08fBvKgyFJ"
      },
      "source": [
        "# Make directory named kaggle and copy kaggle.json file there.\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eELkx9iFhELf"
      },
      "source": [
        "# Change the permissions of the file.\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKDnIW--hGUT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0450b418-86ac-4ecd-fdfb-1797da1c3b1b"
      },
      "source": [
        "#dowload dataset\n",
        "!kaggle datasets download -d kazanova/sentiment140"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sentiment140.zip to /content\n",
            " 90% 73.0M/80.9M [00:03<00:00, 13.8MB/s]\n",
            "100% 80.9M/80.9M [00:03<00:00, 21.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7GEAqvgiE_c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "58c41089-93d1-4c05-a377-dc78b6f7aa84"
      },
      "source": [
        "#unzio dataset\n",
        "!unzip sentiment140.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  sentiment140.zip\n",
            "  inflating: training.1600000.processed.noemoticon.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6CQLNapiXS1"
      },
      "source": [
        "#rename file\n",
        "import os\n",
        "os.rename('training.1600000.processed.noemoticon.csv', 'twitter_sentiment_analysis.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIwpUSRmnFi9"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xthwrZLGnEa8"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import models\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTZlAnhOiHEm"
      },
      "source": [
        "# Explore dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6lUWGjGiyja"
      },
      "source": [
        "# with default encoding i am getting UnicodeDecodeError so use encoding = 'ISO-8859-1\n",
        "# i got solution at https://stackoverflow.com/a/18172249\n",
        "# you can find columns name at dataset link\n",
        "\n",
        "data = pd.read_csv(\"/content/twitter_sentiment_analysis.csv\",encoding='ISO-8859-1',header=None,names=['target','id','date','flag','user','text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdBxKwOsi5dg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "85f9074c-094d-4b79-f1f5-af4efac019d8"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>flag</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810369</td>\n",
              "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>_TheSpecialOne_</td>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810672</td>\n",
              "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>scotthamilton</td>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1467810917</td>\n",
              "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>mattycus</td>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811184</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>ElleCTF</td>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1467811193</td>\n",
              "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
              "      <td>NO_QUERY</td>\n",
              "      <td>Karoli</td>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   target  ...                                               text\n",
              "0       0  ...  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
              "1       0  ...  is upset that he can't update his Facebook by ...\n",
              "2       0  ...  @Kenichan I dived many times for the ball. Man...\n",
              "3       0  ...    my whole body feels itchy and like its on fire \n",
              "4       0  ...  @nationwideclass no, it's not behaving at all....\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaN6AugDHapV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "b6eb9c1a-0a39-42ef-f570-0835e6976e4b"
      },
      "source": [
        "data['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4    800000\n",
              "0    800000\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgAxlgRtlpb0"
      },
      "source": [
        "\n",
        "**csv file contains following fields**\n",
        "\n",
        "* target: the polarity of the tweet (0 = negative 4 = positive)\n",
        "\n",
        "* ids: The id of the tweet\n",
        "\n",
        "* date: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
        "\n",
        "* flag: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
        "\n",
        "* user: the user that tweeted (robotickilldozr)\n",
        "\n",
        "* text: the text of the tweet (Lyx is cool)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6writXsBmRbz"
      },
      "source": [
        "**For our purpuse we need only two fields text and target**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osm1ZCnNkNYN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "c93e4ec2-3b23-4fa4-f11a-5d59f2554ad3"
      },
      "source": [
        "#extract two fields text and target\n",
        "data = data[['text','target']]\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target\n",
              "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...       0\n",
              "1  is upset that he can't update his Facebook by ...       0\n",
              "2  @Kenichan I dived many times for the ball. Man...       0\n",
              "3    my whole body feels itchy and like its on fire        0\n",
              "4  @nationwideclass no, it's not behaving at all....       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DptasrZvmjDk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c53527c-1f14-4d8e-cb11-47d4c4d521f1"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1600000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efEeqDWgmuW7"
      },
      "source": [
        "* **Here we have 1600000 revies with target** <br>\n",
        "* **we can see that text contains some special symbol like @, it might contains some html tags we have to remove it. and target column has 0 and 4 we will convert it into 0 and 1.**<br>\n",
        "* **let pre-process this text**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHTl3asNneCc"
      },
      "source": [
        "# Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6UGC957mm-u"
      },
      "source": [
        "def clean_tweets(tweet):\n",
        "  tweet = BeautifulSoup(tweet).get_text() # remove all html tags\n",
        "  tweet = re.sub(r'@[A-Za-z0-9]+',' ',tweet) # replace each word which start from @ (example : @Kenichan) with space\n",
        "  tweet = re.sub(r'https?://[A-Za-z0-9./]+',' ',tweet) # replace url or links with space\n",
        "  tweet = re.sub(r\"[^A-Za-z.!?']\",' ',tweet) #replace everything exceptspecified in group\n",
        "  tweet = re.sub(r\" +\",' ',tweet) # replace multple white spaces with single space\n",
        "  return tweet\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTMJCSrUqQ98"
      },
      "source": [
        "# convert_labels = {0:0,2:1,4:2}\n",
        "data['text'] = data['text'].apply(clean_tweets)\n",
        "# data['target'] = data['target'].apply(lambda t : convert_labels[t]) # convert target columns into 0,1 and 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHpfaRRxOhvZ"
      },
      "source": [
        "data['target'].replace(4, 1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfkTI50zrF11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b64844ad-667b-475a-861c-e7349d9ef54c"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Awww that's a bummer. You shoulda got David C...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is upset that he can't update his Facebook by ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I dived many times for the ball. Managed to s...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>my whole body feels itchy and like its on fire</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>no it's not behaving at all. i'm mad. why am ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  target\n",
              "0   Awww that's a bummer. You shoulda got David C...       0\n",
              "1  is upset that he can't update his Facebook by ...       0\n",
              "2   I dived many times for the ball. Managed to s...       0\n",
              "3    my whole body feels itchy and like its on fire        0\n",
              "4   no it's not behaving at all. i'm mad. why am ...       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmFNP18PwvLG"
      },
      "source": [
        "**Here we cleaned our text and change value of target field**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ew255xoKwouC"
      },
      "source": [
        "data.to_csv('/content/drive/My Drive/Data/sentiment140/twitter_sentiment_analysis.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08869ppixH_S"
      },
      "source": [
        "## Tokenizing each tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0uaqSog4SNs"
      },
      "source": [
        "data = pd.read_csv('/content/drive/My Drive/Data/sentiment140/twitter_sentiment_analysis.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcPgsxcPE-c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ec98a0cb-694a-4ac7-b40e-e4ec45ed58fe"
      },
      "source": [
        "data['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    800000\n",
              "0    800000\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqEptIqHxRXf"
      },
      "source": [
        "# get both column as list\n",
        "clean_text = data.text.to_list()\n",
        "labels = data.target.to_list()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSAxbwYpEtnn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "71c7b45c-d0ba-423c-fdfe-76cbc82064a9"
      },
      "source": [
        "from collections import Counter\n",
        "Counter(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0: 800000, 1: 800000})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RQyxYKpxgeZ"
      },
      "source": [
        "# build tokenizer\n",
        "# here we will use SubwordTextEncoder which will create token(number) for each word in corpus.\n",
        "# In evaluation if new word comes it will create tokenes base on character or sub word\n",
        "# https://stackoverflow.com/a/58123024 \n",
        "tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(clean_text,target_vocab_size=2**16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW0yu0os9MIQ"
      },
      "source": [
        "# we can save tokenizer\n",
        "tokenizer.save_to_file('/content/drive/My Drive/Data/sentiment140/tokenizer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0Ou4l429OX0"
      },
      "source": [
        "# load tokenizer\n",
        "tokenizer = tfds.features.text.SubwordTextEncoder.load_from_file('/content/drive/My Drive/Data/sentiment140/tokenizer')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzMLS2PgyK6l"
      },
      "source": [
        "text_input = [tokenizer.encode(sentence) for sentence in clean_text]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDx6BFjh2elT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "94a3949b-5623-4955-da7a-cb4bd9e7aba1"
      },
      "source": [
        "print(clean_text[0])\n",
        "print(text_input[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Awww that's a bummer. You shoulda got David Carr of Third Day to do it. D\n",
            "[65316, 1570, 113, 65323, 10, 6, 3553, 1, 135, 5262, 50, 1484, 38165, 16, 13337, 606, 2, 49, 33, 1, 65352]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a50Zn5nH05xa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3abf776-8915-40eb-ce5f-6d2215a636fe"
      },
      "source": [
        "MAX_LEN = max([len(tokenize_sentence) for tokenize_sentence in text_input])\n",
        "MAX_LEN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "73"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9QLq-uv_H1t"
      },
      "source": [
        "# let pad this tokens of sentece to make it equal length (MAX_LEN)\n",
        "# we will pad with 0\n",
        "padded_text_input = tf.keras.preprocessing.sequence.pad_sequences(text_input,maxlen=MAX_LEN,value=0,padding='post',)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqYM2a1M_LZ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "c84220b3-0d3a-4aed-e4b5-3b861a91a1ee"
      },
      "source": [
        "print(\"Tokenizer Sequence : \\n\")\n",
        "print(text_input[0])\n",
        "\n",
        "print(\"\\n\\nPadded Sequence : \\n\")\n",
        "print(padded_text_input[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tokenizer Sequence : \n",
            "\n",
            "[65316, 1570, 113, 65323, 10, 6, 3553, 1, 135, 5262, 50, 1484, 38165, 16, 13337, 606, 2, 49, 33, 1, 65352]\n",
            "\n",
            "\n",
            "Padded Sequence : \n",
            "\n",
            "[65316  1570   113 65323    10     6  3553     1   135  5262    50  1484\n",
            " 38165    16 13337   606     2    49    33     1 65352     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0     0     0     0     0     0     0     0     0     0     0     0\n",
            "     0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMwGmesXCVFe"
      },
      "source": [
        "# Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhR_Z3B0Ayav"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(padded_text_input,labels,test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6hnjVllDtLv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "acdabfaa-140d-4317-b8b8-752f7e081eb0"
      },
      "source": [
        "print(\"Training data consists {} examples\".format(len(X_train)))\n",
        "print(\"Testing data consists {} examples\".format(len(X_test)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data consists 1280000 examples\n",
            "Testing data consists 320000 examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Bzo_huDPHs9"
      },
      "source": [
        "X_train, X_test, y_train, y_test = np.asarray(X_train), np.asarray(X_test), np.asarray(y_train), np.asarray(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrXMyZxrEqK6"
      },
      "source": [
        "# Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2-xT8iUDwP9"
      },
      "source": [
        "class SentimentCNN(tf.keras.Model):\n",
        "\n",
        "  def __init__(self,vocab_size,embedding_dim=128,num_filterS=50,FFN=512,num_classes=2\n",
        "               ,dropout_rate=0.1,training=False,name='sentiment_cnn'):\n",
        "    super(SentimentCNN,self).__init__(name=name)\n",
        "\n",
        "    #define our layers\n",
        "    self.embeddings = tf.keras.layers.Embedding(vocab_size,embedding_dim)\n",
        "\n",
        "    # here we are using Conv1D because we need to convolve only on one axis\n",
        "    self.bigram = tf.keras.layers.Conv1D(filters=num_filterS,kernel_size=2,\n",
        "                                         padding='valid',activation='relu')\n",
        "    self.pool_1  = tf.keras.layers.GlobalAvgPool1D()\n",
        "\n",
        "    self.trigram = tf.keras.layers.Conv1D(filters=num_filterS,kernel_size=3,\n",
        "                                          padding='valid',activation='relu')\n",
        "    self.pool_2  = tf.keras.layers.GlobalAvgPool1D()\n",
        "\n",
        "\n",
        "    self.fourgram = tf.keras.layers.Conv1D(filters=num_filterS,kernel_size=4,\n",
        "                                           padding='valid',activation='relu')\n",
        "    self.pool_3  = tf.keras.layers.GlobalAvgPool1D()\n",
        "\n",
        "    self.dense_1 = tf.keras.layers.Dense(FFN,activation='relu')\n",
        "    self.dropout = tf.keras.layers.Dropout(rate=dropout_rate)\n",
        "\n",
        "    if num_classes == 2:\n",
        "      self.output_layer = tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "    else:\n",
        "      self.output_layer = tf.keras.layers.Dense(num_classes,activation='softmax')\n",
        "\n",
        "  def call(self,input,training):\n",
        "\n",
        "    embeddings = self.embeddings(input)\n",
        "\n",
        "    bigram = self.bigram(embeddings)\n",
        "    bigram_pooled = self.pool_1(bigram)\n",
        "\n",
        "    trigram = self.trigram(embeddings)\n",
        "    trigram_pooled = self.pool_2(trigram)\n",
        "\n",
        "    fourgram = self.fourgram(embeddings)\n",
        "    fourgram_pooled = self.pool_3(fourgram)\n",
        "\n",
        "    merged = tf.concat([bigram_pooled,trigram_pooled,fourgram_pooled],axis=-1) # (batch_size,3*num_filter) 3->because we have bigram trigram and fourgram\n",
        "    merged = self.dense_1(merged)\n",
        "    merged = self.dropout(merged,training)\n",
        "    merged = self.output_layer(merged)\n",
        "\n",
        "    return merged\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3udeVYk7K23O"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBQ5LV12Krk2"
      },
      "source": [
        "VOCAB_SIZE = tokenizer.vocab_size\n",
        "EMBEDDING_SIZE = 256\n",
        "NUM_FILTERS = 64\n",
        "FFN = 512\n",
        "NUM_CLASSES = 2\n",
        "DROPOUT_RATE = 0.2\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCH = 5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5EJ3UL7Lj3T"
      },
      "source": [
        "SentimentCnn = SentimentCNN(VOCAB_SIZE,EMBEDDING_SIZE,NUM_FILTERS,FFN,NUM_CLASSES,DROPOUT_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6AOKJvEL4Md"
      },
      "source": [
        "SentimentCnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EafF-eKNM21F"
      },
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "checkpoint_filepath = '/content/drive/My Drive/Data/sentiment140/checkPoints/'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHQtuY-IOTo7"
      },
      "source": [
        "SentimentCnn.fit(X_train,y_train,validation_data=(X_test,y_test),batch_size=BATCH_SIZE,epochs=NUM_EPOCH,callbacks=[callback,model_checkpoint_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yex6Bjzi_vlo"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzhT67X__u8u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "fd29fc1a-630e-4cb3-f173-1b3774c3df9f"
      },
      "source": [
        "SentimentCnn.save('/content/drive/My Drive/Data/sentiment140/model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Data/sentiment140/model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Data/sentiment140/model/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMcScwHB-w1Y"
      },
      "source": [
        "model = models.load_model('/content/drive/My Drive/Data/sentiment140/model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHsjFYq9-3O9"
      },
      "source": [
        "index_to_sentiment = {0:'negative',1:'positive'}\n",
        "def predict_sentiment(text):\n",
        "  text =  clean_tweets(text)\n",
        "  embedding = tokenizer.encode(text)\n",
        "  embedding = np.expand_dims(embedding,axis=0)\n",
        "  pad_embedding = tf.keras.preprocessing.sequence.pad_sequences(embedding,maxlen=MAX_LEN,value=0,padding='post')\n",
        "  prediction = model.predict(pad_embedding)\n",
        "  \n",
        "  response = {index_to_sentiment[0]:1-prediction[0][0],index_to_sentiment[1]:prediction[0][0]}\n",
        "  return response"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBKii_rtAxP_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6420429c-343b-4f46-909d-90191a4a000b"
      },
      "source": [
        "predict_sentiment('I really like the new design of your website!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'negative': 0.0001634359359741211, 'positive': 0.99983656}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSwkV2O5EOgD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c8880c8-5374-4216-f136-ebded75068b0"
      },
      "source": [
        "predict_sentiment('The new design is awful!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'negative': 0.9328088983893394, 'positive': 0.0671911}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAB-OydnEVUH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae5abe56-8f5b-469c-e477-50f26f0f87e6"
      },
      "source": [
        "predict_sentiment('impossible to reach customer service')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'negative': 0.8121347725391388, 'positive': 0.18786523}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mm1sCfNTEmdW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}